{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZX-pS3iQhav"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFclGDq5QO9h"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/kface/Middle_Resolution.zip'\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/deep_learning/model/yolov5_kface'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEXnbkpKFyNT"
      },
      "source": [
        "# YOLOv5 모델 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkmMLOVpFvUF",
        "outputId": "68a1260e-346b-45b2-c0bc-915d8d909960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14887, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 14887 (delta 0), reused 0 (delta 0), pack-reused 14882\u001b[K\n",
            "Receiving objects: 100% (14887/14887), 13.86 MiB | 11.51 MiB/s, done.\n",
            "Resolving deltas: 100% (10246/10246), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 182 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 41.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrEIdtAOF4gw"
      },
      "source": [
        "# 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTwAe82zF4eG",
        "outputId": "15e36f0f-a3eb-454c-ba83-632c0bbdb08d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5/kface\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "%mkdir /content/yolov5/kface\n",
        "%cd /content/yolov5/kface\n",
        "path = data_path\n",
        "data = zipfile.ZipFile(path, 'r')\n",
        "data.extractall('/content/yolov5/kface')\n",
        "data.close()\n",
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/kface/Middle_Resolution.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBblfU4OPF_Q"
      },
      "source": [
        "# 바운딩 박스 좌표 정규화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGVUVazXtj10"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6aHI0nDF4Hl"
      },
      "outputs": [],
      "source": [
        "img_size = (230, 346) # (h, w)\n",
        "classes=['S001_E01', 'S001_E02', 'S001_E03', 'S002_E01', 'S002_E02', 'S002_E03',\n",
        "         'S003_E01', 'S003_E02', 'S003_E03', 'S004_E01', 'S004_E02', 'S004_E03',\n",
        "         'S005_E01', 'S005_E02', 'S005_E03', 'S006_E01', 'S006_E02', 'S006_E03']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydYEs8-qveJp"
      },
      "outputs": [],
      "source": [
        "txt_paths = sorted(glob.glob('/content/yolov5/kface/*/*.txt'))\n",
        "jpg_paths = sorted(glob.glob('/content/yolov5/kface/*/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cenFF2IMF4EV",
        "outputId": "61177011-bd13-4d37-8954-982223576783"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 93600/93600 [00:20<00:00, 4526.53it/s]\n"
          ]
        }
      ],
      "source": [
        "for txt_path in tqdm(txt_paths):\n",
        "    filename = txt_path.split('/')[-1]\n",
        "    label = txt_path.split('/')[-2]\n",
        "    num_label = classes.index(label)\n",
        "\n",
        "    with open(txt_path, 'rt') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    x, y, w, h = map(int, lines[7].split('\\t'))\n",
        "    x = (x+w/2)/img_size[1]\n",
        "    y = (y+h/2)/img_size[0]\n",
        "    w = w/img_size[1]\n",
        "    h = h/img_size[0]\n",
        "\n",
        "    target_path = '/content/yolov5/kface/train/labels/'+label+'_'+filename\n",
        "    if not os.path.isdir('/content/yolov5/kface/train/labels/'):\n",
        "        os.makedirs('/content/yolov5/kface/train/labels/')\n",
        "    with open(target_path, 'wt') as f:\n",
        "        f.write(f'{num_label} {x} {y} {w} {h}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fepP2eDnrclX",
        "outputId": "e1800207-fd7c-4667-bd64-3f259ee1eec6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 93600/93600 [00:04<00:00, 21025.84it/s]\n"
          ]
        }
      ],
      "source": [
        "for jpg_path in tqdm(jpg_paths):\n",
        "    filename = jpg_path.split('/')[-1]\n",
        "    label = jpg_path.split('/')[-2]\n",
        "\n",
        "    target_path = '/content/yolov5/kface/train/images/'+label+'_'+filename\n",
        "    if not os.path.isdir('/content/yolov5/kface/train/images/'):\n",
        "        os.makedirs('/content/yolov5/kface/train/images/')\n",
        "    shutil.move(jpg_path, target_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMHyEqRn-vBU"
      },
      "outputs": [],
      "source": [
        "# 폴더 정리\n",
        "for cls in classes:\n",
        "    shutil.rmtree('/content/yolov5/kface/'+cls+'/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHi-JWjuPsoi"
      },
      "source": [
        "# 데이터 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9xfE62kPVVk"
      },
      "outputs": [],
      "source": [
        "def split_img_label(data_valid, folder_valid):\n",
        "    \n",
        "    os.makedirs(folder_valid+'images/')\n",
        "    os.makedirs(folder_valid+'labels/')\n",
        "\n",
        "    valid_ind = list(data_valid.index)\n",
        "\n",
        "    # Valid folder\n",
        "    for j in tqdm(range(len(valid_ind))):\n",
        "        shutil.move(data_valid[valid_ind[j]], folder_valid+'images/'+data_valid[valid_ind[j]].split('/')[-1])\n",
        "        shutil.move('/'+os.path.join(*data_valid[valid_ind[j]].split('/')[:-2])+'/labels/'+data_valid[valid_ind[j]].split('/')[-1].split('.jpg')[0]+'.txt', folder_valid+'labels/'+data_valid[valid_ind[j]].split('/')[-1].split('.jpg')[0]+'.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nc3pHZEgKBz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "txt_paths = sorted(glob.glob('/content/yolov5/kface/train/labels/*.txt'))\n",
        "jpg_paths = sorted(glob.glob('/content/yolov5/kface/train/images/*.jpg'))\n",
        "\n",
        "labels = []\n",
        "for txt_path in txt_paths:\n",
        "    with open(txt_path, 'rt') as f:\n",
        "        lines = f.readlines()\n",
        "    labels.append(lines[0].split(' ')[0])\n",
        "\n",
        "labels = pd.DataFrame(labels)\n",
        "df = pd.DataFrame(jpg_paths)\n",
        "df = pd.concat([df, labels], axis=1)\n",
        "df.columns = [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNlE-tHRQjuh",
        "outputId": "8dc82435-8554-433e-a9da-ce67b592b98d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18720/18720 [00:02<00:00, 8304.60it/s]\n"
          ]
        }
      ],
      "source": [
        "# split \n",
        "data_train, data_valid, labels_train, labels_valid = train_test_split(df[0], df[1], test_size=0.2, stratify=df[1], random_state=42)\n",
        "\n",
        "folder_valid_name = '/content/yolov5/kface/valid/'\n",
        "\n",
        "# Function split \n",
        "split_img_label(data_valid, folder_valid_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxE1sJ7vIuJn"
      },
      "outputs": [],
      "source": [
        "# # 데이터 저장\n",
        "# file_path = '/content/yolov5/kface/'\n",
        "# data = zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/kface/data.zip', 'w')\n",
        "# for (path, dir, files) in tqdm(os.walk(file_path)):\n",
        "#     for file in files:\n",
        "#         data.write(os.path.join(path, file), compress_type=zipfile.ZIP_DEFLATED)\n",
        "# data.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26v5D-m8r2q9"
      },
      "source": [
        "# yolo데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DtGc6kXsh1O",
        "outputId": "3dde83fd-9f54-48eb-f0b9-5e9ac81a70bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(74880, 18720)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_img_list = glob.glob('/content/yolov5/kface/train/images/*.jpg')\n",
        "valid_img_list = glob.glob('/content/yolov5/kface/valid/images/*.jpg')\n",
        "len(train_img_list), len(valid_img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9XXyah2zK2f"
      },
      "outputs": [],
      "source": [
        "# 파일 목록 실제 파일로 저장\n",
        "with open('/content/yolov5/kface/train.txt', 'w') as f:\n",
        "    f.write('\\n'.join(train_img_list)+'\\n')\n",
        "\n",
        "with open('/content/yolov5/kface/valid.txt', 'w') as f:\n",
        "    f.write('\\n'.join(valid_img_list)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrp0aAIJEB6s"
      },
      "outputs": [],
      "source": [
        "# yaml 파일 수정을 위한 함수\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49bAT3ylEB4k"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/kface/data.yaml\n",
        "\n",
        "train: ../kface/train/images\n",
        "val: ../kface/valid/images\n",
        "\n",
        "nc: 18\n",
        "names: ['None_Netural', 'None_Happy', 'None_Frown', 'Nomal_Glass_Netural', 'Nomal_Glass_Happy', 'Nomal_Glass_Frown',\n",
        "        'Horn_rimmed_Glass_Netural', 'Horn_rimmed_Glass_Happy', 'Horn_rimmed_Glass_Frown',\n",
        "        'Sunglasses_Netural', 'Sunglasses_Happy', 'Sunglasses_Frown',\n",
        "        'Netual_with_cap', 'Happy_with_cap', 'Frown_with_cap',\n",
        "        'Horn_rimmed_Glass_Netural_with_cap', 'Horn_rimmed_Glass_Happy_with_cap', 'Horn_rimmed_Glass_Frown_with_cap']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxEkmujREB2U",
        "outputId": "96be3c7b-e38f-4910-b426-5ae443ed3f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "train: ../kface/train/images\n",
            "val: ../kface/valid/images\n",
            "\n",
            "nc: 18\n",
            "names: ['None_Netural', 'None_Happy', 'None_Frown', 'Nomal_Glass_Netural', 'Nomal_Glass_Happy', 'Nomal_Glass_Frown',\n",
            "        'Horn_rimmed_Glass_Netural', 'Horn_rimmed_Glass_Happy', 'Horn_rimmed_Glass_Frown',\n",
            "        'Sunglasses_Netural', 'Sunglasses_Happy', 'Sunglasses_Frown',\n",
            "        'Netual_with_cap', 'Happy_with_cap', 'Frown_with_cap',\n",
            "        'Horn_rimmed_Glass_Netural_with_cap', 'Horn_rimmed_Glass_Happy_with_cap', 'Horn_rimmed_Glass_Frown_with_cap']\n"
          ]
        }
      ],
      "source": [
        "%cat /content/yolov5/kface/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKuoz-BAEBzm"
      },
      "source": [
        "# yolo 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d9i8UayIEBxV",
        "outputId": "80fd542c-a207-4812-9e8f-c9ee18410194"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'18'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "with open('/content/yolov5/kface/data.yaml', 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc']) # 클래스 갯수 불러오기\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZNb7Rz4EBsE"
      },
      "outputs": [],
      "source": [
        "# 사본 커스텀 저장\n",
        "%%writetemplate /content/yolov5/models/kface_yolov5s.yaml\n",
        "\n",
        "# Parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 v6.0 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, C3, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 6, C3, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, C3, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 3, C3, [1024]],\n",
        "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 v6.0 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, C3, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttQsk0gvEBpM",
        "outputId": "28e8bd26-c19d-4d23-d74c-7c5b802e1088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "# Parameters\n",
            "nc: 18  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ],
      "source": [
        "# 수정 확인\n",
        "%cat /content/yolov5/models/kface_yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCEuPga7EBmN",
        "outputId": "59ca5743-3098-4fcd-d72e-b58a04c054b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTaIaIkREBjM",
        "outputId": "3fa4113e-667f-425e-813e-0988fe6c592f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/kface_yolov5s.yaml, data=./kface/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=32, imgsz=346, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=kface_result, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-49-g3c1afd9 Python-3.8.16 torch-1.13.0+cu116 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 2.78MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 15.6MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     62031  models.yolo.Detect                      [18, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "kface_YOLOv5s summary: 214 layers, 7068175 parameters, 7068175 gradients, 16.1 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5s.pt\n",
            "WARNING ⚠️ --img-size 346 must be multiple of max stride 32, updating to 352\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/kface/train/labels... 74880 images, 0 backgrounds, 0 corrupt: 100% 74880/74880 [00:47<00:00, 1584.97it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/kface/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m17.2GB RAM required, 10.9/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/kface/valid/labels... 18720 images, 0 backgrounds, 0 corrupt: 100% 18720/18720 [00:14<00:00, 1258.65it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/kface/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.3GB ram): 100% 18720/18720 [00:46<00:00, 401.83it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.23 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/kface_result/labels.jpg... \n",
            "Image sizes 352 train, 352 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/kface_result\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19         0G     0.1135    0.01863     0.0798         82        352:   1% 24/2340 [06:02<9:43:04, 15.11s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 309, in train\n",
            "    pred = model(imgs)  # forward\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/yolo.py\", line 209, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/yolov5/models/yolo.py\", line 121, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 168, in forward\n",
            "    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 57, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 634, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 528, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"train.py\", line 309, in train\n",
            "    pred = model(imgs)  # forward\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "CPU times: user 5.61 s, sys: 858 ms, total: 6.47 s\n",
            "Wall time: 8min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python train.py --img 346 --batch 32 --epochs 20 --data ./kface/data.yaml \\\n",
        "--cfg ./models/kface_yolov5s.yaml --name kface_result --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PL7WZ5i0Ff3j",
        "outputId": "f8bb00e0-abe7-44d1-dc9b-5c40ad56036f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QzeWB31VFf00",
        "outputId": "86817d61-88e4-494a-b674-59889fde0b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1672072191.be5713d6e51b.1117.0  train_batch0.jpg\n",
            "hyp.yaml\t\t\t\t\t    train_batch1.jpg\n",
            "labels_correlogram.jpg\t\t\t\t    train_batch2.jpg\n",
            "labels.jpg\t\t\t\t\t    weights\n",
            "opt.yaml\n"
          ]
        }
      ],
      "source": [
        "!ls /content/yolov5/runs/train/kface_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CZUcez5rFfyL",
        "outputId": "52e653b6-6709-4229-9bd9-008c36b93dbf"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-568409ec160e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov5/runs/train/kface_result/results.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1204\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov5/runs/train/kface_result/results.png'"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='/content/yolov5/runs/train/kface_result/results.png', width=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jK0n9wvGFfvm"
      },
      "outputs": [],
      "source": [
        "Image(filename='/content/yolov5/runs/train/kface_result/train_batch0.jpg', width=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ago5Gtj9Ffs1"
      },
      "outputs": [],
      "source": [
        "Image(filename='/content/yolov5/runs/train/kface_result/val_batch0_labels.jpg', width=800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNGawNMgsTLz"
      },
      "source": [
        "# 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hg9Oz0ZSFfqD"
      },
      "outputs": [],
      "source": [
        "# validation data\n",
        "!python val.py --weights runs/train/kface_result/weights/best.pt \\\n",
        "--data ./kface/data.yaml --img 864 --iou 0.65 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OZzdHMneFfnF"
      },
      "outputs": [],
      "source": [
        "# # test data\n",
        "# !python val.py --weights runs/train/kface_result/weights/best.pt \\\n",
        "# --data ./kface/data.yaml --img 864 --task test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUQ2gspVstsB"
      },
      "source": [
        "# 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_TehdZFNFfkT"
      },
      "outputs": [],
      "source": [
        "%cp /content/yolov5/runs/train/kface_result3/weights/best.pt model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fiH_2qoUssgJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}